<!DOCTYPE html><html lang="en-gb"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Determining the Effects of Different Parameters in Neural Network Creation - The Study</title><meta name="description" content="While the architechture of a neural network can be easily accomplished with a few lines of code, building one from the ground up helps to ensure clarity and that each part works as it should. Further, it allows us to alter each part of the&hellip;"><meta name="generator" content="Publii Open-Source CMS for Static Site"><link rel="canonical" href="https://chandownbytheriver.github.io/creating-a-neural-network-to-determine-the-strength-of-concrete.html"><link rel="alternate" type="application/atom+xml" href="https://chandownbytheriver.github.io/feed.xml"><link rel="alternate" type="application/json" href="https://chandownbytheriver.github.io/feed.json"><meta property="og:title" content="Determining the Effects of Different Parameters in Neural Network Creation"><meta property="og:image" content="https://chandownbytheriver.github.io/media/website/Q3svdBhDQtubBB8M7CVI-1-1bsc1.jpg"><meta property="og:image:width" content="1024"><meta property="og:image:height" content="1024"><meta property="og:site_name" content="The Study"><meta property="og:description" content="While the architechture of a neural network can be easily accomplished with a few lines of code, building one from the ground up helps to ensure clarity and that each part works as it should. Further, it allows us to alter each part of the&hellip;"><meta property="og:url" content="https://chandownbytheriver.github.io/creating-a-neural-network-to-determine-the-strength-of-concrete.html"><meta property="og:type" content="article"><link rel="stylesheet" href="https://chandownbytheriver.github.io/assets/css/style.css?v=6fbb1e8931a5afe843374fd67c192c86"><script type="application/ld+json">{"@context":"http://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://chandownbytheriver.github.io/creating-a-neural-network-to-determine-the-strength-of-concrete.html"},"headline":"Determining the Effects of Different Parameters in Neural Network Creation","datePublished":"2024-03-01T12:05","dateModified":"2024-03-15T15:57","image":{"@type":"ImageObject","url":"https://chandownbytheriver.github.io/media/website/Q3svdBhDQtubBB8M7CVI-1-1bsc1.jpg","height":1024,"width":1024},"description":"While the architechture of a neural network can be easily accomplished with a few lines of code, building one from the ground up helps to ensure clarity and that each part works as it should. Further, it allows us to alter each part of the&hellip;","author":{"@type":"Person","name":"Chandler Rottenberg","url":"https://chandownbytheriver.github.io/authors/chandler-rottenberg/"},"publisher":{"@type":"Organization","name":"Chandler Rottenberg","logo":{"@type":"ImageObject","url":"https://chandownbytheriver.github.io/media/website/Q3svdBhDQtubBB8M7CVI-1-1bsc1.jpg","height":1024,"width":1024}}}</script><noscript><style>img[loading] {
                    opacity: 1;
                }</style></noscript></head><body><div class="site-container"><header class="top" id="js-header"><a class="logo" href="https://chandownbytheriver.github.io/"><img src="https://chandownbytheriver.github.io/media/website/Q3svdBhDQtubBB8M7CVI-1-1bsc1.jpg" alt="The Study" width="1024" height="1024"></a></header><main><article class="post"><div class="hero"><figure class="hero__image hero__image--overlay"><img src="https://chandownbytheriver.github.io/media/website/DALLE_2023-12-03_20.19.20_-_Create_an_artistic_image_of_a_sophisticated_study_belonging_to_a_character_named_SMITH_who_is_working_on_the_PRISM_light-based_computing_project._The.png" srcset="https://chandownbytheriver.github.io/media/website/responsive/DALLE_2023-12-03_20.19.20_-_Create_an_artistic_image_of_a_sophisticated_study_belonging_to_a_character_named_SMITH_who_is_working_on_the_PRISM_light-based_computing_project._The-xs.png 300w, https://chandownbytheriver.github.io/media/website/responsive/DALLE_2023-12-03_20.19.20_-_Create_an_artistic_image_of_a_sophisticated_study_belonging_to_a_character_named_SMITH_who_is_working_on_the_PRISM_light-based_computing_project._The-sm.png 480w, https://chandownbytheriver.github.io/media/website/responsive/DALLE_2023-12-03_20.19.20_-_Create_an_artistic_image_of_a_sophisticated_study_belonging_to_a_character_named_SMITH_who_is_working_on_the_PRISM_light-based_computing_project._The-md.png 768w, https://chandownbytheriver.github.io/media/website/responsive/DALLE_2023-12-03_20.19.20_-_Create_an_artistic_image_of_a_sophisticated_study_belonging_to_a_character_named_SMITH_who_is_working_on_the_PRISM_light-based_computing_project._The-lg.png 1024w, https://chandownbytheriver.github.io/media/website/responsive/DALLE_2023-12-03_20.19.20_-_Create_an_artistic_image_of_a_sophisticated_study_belonging_to_a_character_named_SMITH_who_is_working_on_the_PRISM_light-based_computing_project._The-xl.png 1360w, https://chandownbytheriver.github.io/media/website/responsive/DALLE_2023-12-03_20.19.20_-_Create_an_artistic_image_of_a_sophisticated_study_belonging_to_a_character_named_SMITH_who_is_working_on_the_PRISM_light-based_computing_project._The-2xl.png 1600w" sizes="100vw" loading="eager" alt=""></figure><header class="hero__content"><div class="wrapper"><div class="post__meta"><time datetime="2024-03-01T12:05">March 1, 2024</time></div><h1>Determining the Effects of Different Parameters in Neural Network Creation</h1><div class="post__meta post__meta--author"><a href="https://chandownbytheriver.github.io/authors/chandler-rottenberg/" class="feed__author">Chandler Rottenberg</a></div></div></header></div><div class="wrapper post__entry"><p>     While the architechture of a neural network can be easily accomplished with a few lines of code, building one from the ground up helps to ensure clarity and that each part works as it should. Further, it allows us to alter each part of the network one by one to find the optimal parameters for different situations. How do different numbers of epochs increase or decrease accuracy?</p><figure class="post__image"><img loading="lazy" src="https://chandownbytheriver.github.io/media/posts/2/basiclibraries.PNG" alt="" width="421" height="145" sizes="100vw" srcset="https://chandownbytheriver.github.io/media/posts/2/responsive/basiclibraries-xs.PNG 300w, https://chandownbytheriver.github.io/media/posts/2/responsive/basiclibraries-sm.PNG 480w, https://chandownbytheriver.github.io/media/posts/2/responsive/basiclibraries-md.PNG 768w, https://chandownbytheriver.github.io/media/posts/2/responsive/basiclibraries-lg.PNG 1024w, https://chandownbytheriver.github.io/media/posts/2/responsive/basiclibraries-xl.PNG 1360w, https://chandownbytheriver.github.io/media/posts/2/responsive/basiclibraries-2xl.PNG 1600w"></figure><p>We'll start off by loading Keras for the model's formatting as well as pandas and SciKit Learn for statistics and equations.</p><p>Next, we'll load up our data file and generate a description of the dataset. Further, we'll check for any missing values that might require cleaning.</p><figure class="post__image"><img loading="lazy" src="https://chandownbytheriver.github.io/media/posts/2/concdatadesc.PNG" alt="" width="1054" height="647" sizes="100vw" srcset="https://chandownbytheriver.github.io/media/posts/2/responsive/concdatadesc-xs.PNG 300w, https://chandownbytheriver.github.io/media/posts/2/responsive/concdatadesc-sm.PNG 480w, https://chandownbytheriver.github.io/media/posts/2/responsive/concdatadesc-md.PNG 768w, https://chandownbytheriver.github.io/media/posts/2/responsive/concdatadesc-lg.PNG 1024w, https://chandownbytheriver.github.io/media/posts/2/responsive/concdatadesc-xl.PNG 1360w, https://chandownbytheriver.github.io/media/posts/2/responsive/concdatadesc-2xl.PNG 1600w"></figure><p>The data seems to be rather evenly distributed around the mean, with two standard deviations bringing us close to our minimum and max. We can also see that none of the features contain empty cells. With no outliers or missing values this data is ready to be analyzed. </p><p> </p><figure class="post__image"><img loading="lazy" src="https://chandownbytheriver.github.io/media/posts/2/traintestsplit-2.PNG" alt="" width="915" height="110" sizes="100vw" srcset="https://chandownbytheriver.github.io/media/posts/2/responsive/traintestsplit-2-xs.PNG 300w, https://chandownbytheriver.github.io/media/posts/2/responsive/traintestsplit-2-sm.PNG 480w, https://chandownbytheriver.github.io/media/posts/2/responsive/traintestsplit-2-md.PNG 768w, https://chandownbytheriver.github.io/media/posts/2/responsive/traintestsplit-2-lg.PNG 1024w, https://chandownbytheriver.github.io/media/posts/2/responsive/traintestsplit-2-xl.PNG 1360w, https://chandownbytheriver.github.io/media/posts/2/responsive/traintestsplit-2-2xl.PNG 1600w"></figure><p>We'll separate the data into the features that determine the output, and the targetted prediction column.</p><figure class="post__image"><img loading="lazy" src="https://chandownbytheriver.github.io/media/posts/2/regnnnotstandarized.PNG" alt="" width="944" height="351" sizes="100vw" srcset="https://chandownbytheriver.github.io/media/posts/2/responsive/regnnnotstandarized-xs.PNG 300w, https://chandownbytheriver.github.io/media/posts/2/responsive/regnnnotstandarized-sm.PNG 480w, https://chandownbytheriver.github.io/media/posts/2/responsive/regnnnotstandarized-md.PNG 768w, https://chandownbytheriver.github.io/media/posts/2/responsive/regnnnotstandarized-lg.PNG 1024w, https://chandownbytheriver.github.io/media/posts/2/responsive/regnnnotstandarized-xl.PNG 1360w, https://chandownbytheriver.github.io/media/posts/2/responsive/regnnnotstandarized-2xl.PNG 1600w"></figure><p>Next, we'll create a loop for the process of running the model. The data training and testing split is created, and then the model is initialized. The amount of input nodes is equal to the amount of features. There will be one hidden calculation layer between the input and the output. The Rectified Linear Unit (RELU) activation function will be used for higher efficiency and its ability to allow learning off of complex patterns. </p><p>To start out, the Neural Network will go through 50 epochs. After each epoch, variable weights will be updated based on what the network learned in the last epoch. After each epoch, we will gather the mean squared error so that we see how accuracy progresses through training.</p><p>By placing the train and test split as well as model generation in a loop we can get a sense of how the model will perform not just once, but however many times we'd like to see. This helps to ensure that our results aren't a fluke, but rather an accurate representation of how the model works. The model will not use the previous iteration's insights when making the next one. It's a fresh start each time.</p><figure class="post__image"><img loading="lazy" src="https://chandownbytheriver.github.io/media/posts/2/nonstandardresults.PNG" alt="" width="723" height="249" sizes="100vw" srcset="https://chandownbytheriver.github.io/media/posts/2/responsive/nonstandardresults-xs.PNG 300w, https://chandownbytheriver.github.io/media/posts/2/responsive/nonstandardresults-sm.PNG 480w, https://chandownbytheriver.github.io/media/posts/2/responsive/nonstandardresults-md.PNG 768w, https://chandownbytheriver.github.io/media/posts/2/responsive/nonstandardresults-lg.PNG 1024w, https://chandownbytheriver.github.io/media/posts/2/responsive/nonstandardresults-xl.PNG 1360w, https://chandownbytheriver.github.io/media/posts/2/responsive/nonstandardresults-2xl.PNG 1600w"></figure><p>Here we have our measures of accuracy gathered from the neural network's prediction performances. We can see from the Mean Squared Error and its standard deviation that this model produces answers at an average of just under 16 points away from the true label. We can also see that the model varies pretty widely from iteration to iteration. Is there anything we can do about that? </p><p>Perhaps by normalizing the data we can produce more accurate and consistent results.</p><figure class="post__image"><img loading="lazy" src="https://chandownbytheriver.github.io/media/posts/2/normalize.PNG" alt="" width="891" height="177" sizes="100vw" srcset="https://chandownbytheriver.github.io/media/posts/2/responsive/normalize-xs.PNG 300w, https://chandownbytheriver.github.io/media/posts/2/responsive/normalize-sm.PNG 480w, https://chandownbytheriver.github.io/media/posts/2/responsive/normalize-md.PNG 768w, https://chandownbytheriver.github.io/media/posts/2/responsive/normalize-lg.PNG 1024w, https://chandownbytheriver.github.io/media/posts/2/responsive/normalize-xl.PNG 1360w, https://chandownbytheriver.github.io/media/posts/2/responsive/normalize-2xl.PNG 1600w"></figure><p>We will place the normalization into the loop and after the train/test split to ensure that the generated averages aren't affected by data that is hidden in the testing set.</p><p>We'll proceed with the same model architechture otherwise, to see what effect this has.</p><figure class="post__image"><img loading="lazy" src="https://chandownbytheriver.github.io/media/posts/2/normalizeresults-2.PNG" alt="" width="507" height="42" sizes="100vw" srcset="https://chandownbytheriver.github.io/media/posts/2/responsive/normalizeresults-2-xs.PNG 300w, https://chandownbytheriver.github.io/media/posts/2/responsive/normalizeresults-2-sm.PNG 480w, https://chandownbytheriver.github.io/media/posts/2/responsive/normalizeresults-2-md.PNG 768w, https://chandownbytheriver.github.io/media/posts/2/responsive/normalizeresults-2-lg.PNG 1024w, https://chandownbytheriver.github.io/media/posts/2/responsive/normalizeresults-2-xl.PNG 1360w, https://chandownbytheriver.github.io/media/posts/2/responsive/normalizeresults-2-2xl.PNG 1600w"></figure><p>Interestingly, our error margin has increased, but the clustering has grown tighter. Perhaps by changing the structure of our neural network, we can reduce both.</p><figure class="post__image"><img loading="lazy" src="https://chandownbytheriver.github.io/media/posts/2/morehidden.PNG" alt="" width="487" height="79" sizes="100vw" srcset="https://chandownbytheriver.github.io/media/posts/2/responsive/morehidden-xs.PNG 300w, https://chandownbytheriver.github.io/media/posts/2/responsive/morehidden-sm.PNG 480w, https://chandownbytheriver.github.io/media/posts/2/responsive/morehidden-md.PNG 768w, https://chandownbytheriver.github.io/media/posts/2/responsive/morehidden-lg.PNG 1024w, https://chandownbytheriver.github.io/media/posts/2/responsive/morehidden-xl.PNG 1360w, https://chandownbytheriver.github.io/media/posts/2/responsive/morehidden-2xl.PNG 1600w"></figure><p>We'll see how adding two more hidden layers will affect the accuracy of predictions. Everything else will remain the same.</p><figure class="post__image"><img loading="lazy" src="https://chandownbytheriver.github.io/media/posts/2/mhidresults.PNG" alt="" width="512" height="44" sizes="100vw" srcset="https://chandownbytheriver.github.io/media/posts/2/responsive/mhidresults-xs.PNG 300w, https://chandownbytheriver.github.io/media/posts/2/responsive/mhidresults-sm.PNG 480w, https://chandownbytheriver.github.io/media/posts/2/responsive/mhidresults-md.PNG 768w, https://chandownbytheriver.github.io/media/posts/2/responsive/mhidresults-lg.PNG 1024w, https://chandownbytheriver.github.io/media/posts/2/responsive/mhidresults-xl.PNG 1360w, https://chandownbytheriver.github.io/media/posts/2/responsive/mhidresults-2xl.PNG 1600w"></figure><p>Allowing the neural network more steps to understand the connections between variables and outcomes predicatably reduced both MSE and the standard deviation of the MSE. </p><p>The predictions are now, on average, within 9.76 (square root of 95.27) of the true label. This is within the realm of a prediction that could be relied upon. These changes have resulted in a 37.4% increase in accuracy compared to our first model.</p></div><footer class="wrapper post__footer"><p class="post__last-updated">This article was updated on March 15, 2024</p><div class="post__share"></div><div class="post__bio bio"><div><h3 class="bio__name"><a href="https://chandownbytheriver.github.io/authors/chandler-rottenberg/" rel="author">Chandler Rottenberg</a></h3></div></div></footer></article><nav class="post__nav"><div class="post__nav-inner"><div class="post__nav-prev"><svg width="1.041em" height="0.416em" aria-hidden="true"><use xlink:href="https://chandownbytheriver.github.io/assets/svg/svg-map.svg#arrow-prev"/></svg> <a href="https://chandownbytheriver.github.io/simple-and-multiple-linear-regression-projects.html" class="post__nav-link" rel="prev"><span>Previous</span> Improving Accuracy by Using Multiple Linear Regression</a></div><div class="post__nav-next"><a href="https://chandownbytheriver.github.io/using-noise-vectors-in-logistic-regression.html" class="post__nav-link" rel="next"><span>Next</span> Using Noise Vectors in Logistic Regression </a><svg width="1.041em" height="0.416em" aria-hidden="true"><use xlink:href="https://chandownbytheriver.github.io/assets/svg/svg-map.svg#arrow-next"/></svg></div></div></nav></main><footer class="footer"><div class="footer__copyright"><p>Powered by Publii</p></div><button onclick="backToTopFunction()" id="backToTop" class="footer__bttop" aria-label="Back to top" title="Back to top"><svg><use xlink:href="https://chandownbytheriver.github.io/assets/svg/svg-map.svg#toparrow"/></svg></button></footer></div><script defer="defer" src="https://chandownbytheriver.github.io/assets/js/scripts.min.js?v=f47c11534595205f20935f0db2a62a85"></script><script>window.publiiThemeMenuConfig={mobileMenuMode:'sidebar',animationSpeed:300,submenuWidth: 'auto',doubleClickTime:500,mobileMenuExpandableSubmenus:true,relatedContainerForOverlayMenuSelector:'.top'};</script><script>var images = document.querySelectorAll('img[loading]');
        for (var i = 0; i < images.length; i++) {
            if (images[i].complete) {
                images[i].classList.add('is-loaded');
            } else {
                images[i].addEventListener('load', function () {
                    this.classList.add('is-loaded');
                }, false);
            }
        }</script></body></html>